# -*- coding: utf-8 -*-
"""zadanie.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15n5V62gir4gq6QaYwgq9It8o8jOUGZfo
"""

# https://www.kaggle.com/code/sounaksarkar/100-sports-image-classification/notebook

import os
import pandas as pd
import matplotlib.pyplot as plt
import cv2
import numpy as np
import collections
import keras
import tensorflow as tf

from google.colab import drive
from pathlib import Path
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.preprocessing import image
from IPython.display import display, Image
from tensorflow.keras.models import Model
from keras.models import Sequential
from keras.layers import Dense
from keras.layers.convolutional import Conv2D
from keras.layers.convolutional import MaxPooling2D
from keras.layers import GlobalAveragePooling2D
from keras.layers import Flatten
from keras.layers import Dropout
from google.colab.patches import cv2_imshow
from sklearn.cluster import KMeans
from sklearn.metrics import ConfusionMatrixDisplay
from sklearn.metrics import confusion_matrix

drive.mount('/content/drive')
data_path = '/content/drive/MyDrive/SUNS/zadanie3/'
train_data_path = Path(data_path + 'train/')
test_data_path = Path(data_path + 'test/')
valid_data_path = Path(data_path + 'valid/')

train_data_path.glob(r'**/*.jpg')
test_data_path.glob(r'**/*.jpg')
valid_data_path.glob(r'**/*.jpg')

train_data_path

train_filepath = list(train_data_path.glob(r'**/*.jpg'))
valid_filepath = list(valid_data_path.glob(r'**/*.jpg'))
test_filepath = list(test_data_path.glob(r'**/*.jpg'))

classes_train = list(map(lambda x: os.path.split(os.path.split(x)[0])[1],train_filepath) )
classes_valid = list(map(lambda x: os.path.split(os.path.split(x)[0])[1],valid_filepath))
classes_test = list(map(lambda x: os.path.split(os.path.split(x)[0])[1],test_filepath))

count = dict(collections.Counter(classes_train))

# https://stackoverflow.com/questions/16010869/plot-a-bar-using-matplotlib-using-a-dictionary
plt.bar(*zip(*count.items()), width=0.5, linewidth=3.0)
plt.rcParams['figure.figsize'] = [150,50]

plt.show()

labels = []
sizes = []

for x, y in count.items():
    labels.append(x)
    sizes.append(y)

# Plot
plt.pie(sizes, labels=labels)

plt.axis('equal')
plt.show()

# https://stackoverflow.com/questions/9835762/how-do-i-find-the-duplicates-in-a-list-and-create-another-list-with-them
def thg435(l):
    return [x for x, y in collections.Counter(l).items() if y > 1]

# https://www.delftstack.com/howto/python/opencv-average-color-of-image/
def visualize_Dominant_colors(cluster, C_centroids):
    C_labels = np.arange(0, len(np.unique(cluster.labels_)) + 1)
    (C_hist, _) = np.histogram(cluster.labels_, bins = C_labels)
    C_hist = C_hist.astype("float")
    C_hist /= C_hist.sum()

    rect_color = np.zeros((50, 300, 3), dtype=np.uint8)
    img_colors = sorted([(percent, color) for (percent, color) in zip(C_hist, C_centroids)])
    start = 0
    for (percent, color) in img_colors:
        print(color, "{:0.2f}%".format(percent * 100))
        end = start + (percent * 300)
        cv2.rectangle(rect_color, (int(start), 0), (int(end), 50), \
                      color.astype("uint8").tolist(), -1)
        start = end
    return rect_color

# https://stackoverflow.com/questions/31613409/how-to-select-the-first-file-in-a-directory


classes_train_no_duplicates = thg435(classes_train)

for img_class in classes_train_no_duplicates:
  path = str(train_data_path) + '/' + img_class
  folder_walk = os.walk(path)
  first_file_in_folder = next(folder_walk)[2][0]
  img = path + '/' + first_file_in_folder
  print(img_class)

  src_img  = cv2.imread(img)
  average_color_row = np.average(src_img, axis=0)
  average_color = np.average(average_color_row, axis=0)
  print(average_color)

  src_image = cv2.cvtColor(src_img, cv2.COLOR_BGR2RGB)
  reshape_img = src_image.reshape((src_image.shape[0] * src_image.shape[1], 3)) 

  KM_cluster = KMeans(n_clusters=5).fit(reshape_img)
  visualize_color = visualize_Dominant_colors(KM_cluster, KM_cluster.cluster_centers_)
  visualize_color = cv2.cvtColor(visualize_color, cv2.COLOR_RGB2BGR)
  cv2.waitKey()

  d_img = np.ones((224,224,3), dtype=np.uint8)
  d_img[:,:] = average_color

  cv2_imshow(src_img)
  cv2_imshow(d_img)
  cv2_imshow(src_image)
  cv2_imshow( visualize_color)
  cv2.waitKey(0)
  print(src_img.shape)

train_df = pd.concat([pd.Series(train_filepath).astype(str), pd.Series(classes_train)], axis=1)
train_df.columns = ['Images', 'Image_label']

test_df = pd.concat([pd.Series(test_filepath).astype(str), pd.Series(classes_test)], axis=1)
test_df.columns = ['Images', 'Image_label']

valid_df = pd.concat([pd.Series(valid_filepath).astype(str), pd.Series(classes_valid)], axis=1)
valid_df.columns = ['Images', 'Image_label']

train_datagen = ImageDataGenerator(rescale = 1/255,
                                  #  rotation_range = 40, 
                                  #  width_shift_range = 0.2, 
                                  #  height_shift_range = 0.2, 
                                  #  shear_range = 0.2, 
                                  #  zoom_range = 0.2, 
                                  #  horizontal_flip = True, 
                                  #  vertical_flip =True 
                                   )

test_datagen = ImageDataGenerator(rescale = 1/255)

train_gen = train_datagen.flow_from_dataframe(dataframe = train_df,
                                              x_col = 'Images', 
                                              y_col ='Image_label',
                                              target_size = (32,32), batch_size = 512, 
                                              class_mode = 'categorical', 
                                              shuffle = True)
val_gen = train_datagen.flow_from_dataframe(valid_df, 
                                            target_size=(32,32), 
                                            x_col = 'Images', 
                                            y_col ='Image_label', 
                                            class_mode='categorical',
                                            batch_size=  512, 
                                            shuffle=True)
test_gen = test_datagen.flow_from_dataframe(test_df,
                                            target_size = (32,32), x_col = 'Images', y_col ='Image_label',
                                             class_mode = 'categorical',
                                            batch_size = 512, shuffle = False)

# https://www.tensorflow.org/tutorials/images/classification?fbclid=IwAR0MekBg88c56N9FUx0bHlgcFO2MPVtYxQ6c4xtObuVIdns06hErfiLGTHA

model = Sequential()
model.add(Conv2D(64,3, padding='same', input_shape=(32,32,3), activation='relu'))

model.add(MaxPooling2D())

model.add(Conv2D(128,3, padding='same', activation='relu'))

model.add(MaxPooling2D())

model.add(Conv2D(128,3, padding='same', activation='relu'))

model.add(MaxPooling2D())

model.add(Flatten())

model.add(Dense(128, activation='relu'))
#model.add(Dropout(0.2))
          
model.add(Dense(100,activation='softmax'))

optimizer = keras.optimizers.Adam(learning_rate=0.01)

model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics = ['accuracy'], run_eagerly=True)
print(model.summary())

es = keras.callbacks.EarlyStopping(monitor="val_loss", patience=3);

checkpoint = tf.keras.callbacks.ModelCheckpoint(
    filepath = data_path + 'checkpoints/',
    save_weights_only = True,
    monitor = "val_accuracy",
    mode = "max",
    save_best_only = True)

callbacks_list = [checkpoint, es]

history = model.fit(
    train_gen,
    # steps_per_epoch = train_gen.n // train_gen.batch_size,
    validation_data = val_gen,
    # validation_steps = val_gen.n // val_gen.batch_size,
    epochs = 16,
    callbacks = callbacks_list,
    )

model.save_weights('weights.h5')

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

loss = history.history['loss']
val_loss = history.history['val_loss']

plt.figure(figsize=(8, 8))
plt.subplot(2, 1, 1)
plt.plot(acc, label='Training Accuracy')
plt.plot(val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.ylabel('Accuracy')
plt.title('Training and Validation Accuracy')

plt.subplot(2, 1, 2)
plt.plot(loss, label='Training Loss')
plt.plot(val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.ylabel('Cross Entropy')
plt.title('Training and Validation Loss')
plt.xlabel('epoch')
plt.show()

# _, acc = model.evaluate(val_gen, steps = val_gen.n // val_gen.batch_size)
# print('Validation Accuracy: ', (acc * 100))

test_gen.reset()
pred = model.predict(test_gen)

# _, acc = model.evaluate(test_gen, steps = test_gen.n//test_gen.batch_size)
# print('Test Accuracy: ', (acc * 100))

y_pred = np.argmax(pred,axis=1)
y_test = test_gen.classes

conf_mat = confusion_matrix(y_test, y_pred)

fig, cm = plt.subplots(figsize=(10, 10))
disp = ConfusionMatrixDisplay(confusion_matrix = conf_mat, display_labels = labels)
disp.plot(cmap=plt.cm.Blues, ax=cm)
plt.xticks(rotation=90)
plt.show()